{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99c262b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import math\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b35f7b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRCNN(nn.Module):\n",
    "    def __init__(self, num_channels=1):\n",
    "        super(SRCNN, self).__init__()\n",
    "        # Larger kernels for better receptive field\n",
    "        self.layer1 = nn.Conv2d(num_channels, 128, kernel_size=11, padding=5, stride=1)  # Big kernel for initial feature extraction\n",
    "        self.layer2 = nn.Conv2d(128, 128, kernel_size=9, padding=4, stride=1)           # Still big\n",
    "        self.layer3 = nn.Conv2d(128, 64, kernel_size=7, padding=3, stride=1)            # Slightly smaller\n",
    "        self.layer4 = nn.Conv2d(64, 64, kernel_size=5, padding=2, stride=1)\n",
    "        self.layer5 = nn.Conv2d(64, num_channels, kernel_size=5, padding=2, stride=1)   # Output layer\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.relu(self.layer3(x))\n",
    "        x = self.relu(self.layer4(x))\n",
    "        x = self.layer5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57e2e6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRDataset(Dataset):\n",
    "    def __init__(self, lr_dir, hr_dir, transform=None):\n",
    "        self.lr_dir = lr_dir\n",
    "        self.hr_dir = hr_dir\n",
    "        self.lr_images = sorted(os.listdir(lr_dir))\n",
    "        self.hr_images = sorted(os.listdir(hr_dir))\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.lr_images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        lr_path = os.path.join(self.lr_dir, self.lr_images[idx])\n",
    "        hr_path = os.path.join(self.hr_dir, self.hr_images[idx])\n",
    "        \n",
    "        lr_img = Image.open(lr_path).convert(\"YCbCr\").split()[0]\n",
    "        hr_img = Image.open(hr_path).convert(\"YCbCr\").split()[0]\n",
    "        \n",
    "        if self.transform:\n",
    "            lr_img = self.transform(lr_img)\n",
    "            hr_img = self.transform(hr_img)\n",
    "        \n",
    "        return lr_img, hr_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5cf2c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_psnr(pred, target):\n",
    "    mse = torch.mean((pred - target) ** 2)\n",
    "    if mse == 0:\n",
    "        return 100.0\n",
    "    return 20 * math.log10(1.0 / math.sqrt(mse.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6215fb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    This runs AFTER each training epoch\n",
    "    Calculates validation loss and PSNR\n",
    "    \"\"\"\n",
    "    model.eval()  # Set to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    val_psnr = 0.0\n",
    "    \n",
    "    with torch.no_grad():  # No gradient calculation\n",
    "        for lr, hr in val_loader:\n",
    "            lr, hr = lr.to(device), hr.to(device)\n",
    "            output = model(lr)\n",
    "            loss = criterion(output, hr)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            val_psnr += calculate_psnr(output, hr)\n",
    "    \n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    avg_val_psnr = val_psnr / len(val_loader)\n",
    "    \n",
    "    return avg_val_loss, avg_val_psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1edc6b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4          # Try: 8, 16, 32\n",
    "LEARNING_RATE = 1e-4     # Try: 1e-3, 1e-4, 5e-5\n",
    "NUM_EPOCHS = 10         # Try: 50, 100, 150\n",
    "WEIGHT_DECAY = 1e-5      # L2 regularization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5c6195b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# 5. Data Preparation\n",
    "# -----------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e983701d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "train_dataset = SRDataset(\"/home/akanksh/Akshu/ML/project/dataset/train/low_res\", \"/home/akanksh/Akshu/ML/project/dataset/train/high_res\", transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Validation data\n",
    "val_dataset = SRDataset(\"/home/akanksh/Akshu/ML/project/dataset/val/low_res\", \"/home/akanksh/Akshu/ML/project/dataset/val/high_res\", transform=transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f355117e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using device: cuda\n",
      "Model parameters: 1848385\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SRCNN().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "print(f\"\\nUsing device: {device}\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cead375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING STARTED\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     21\u001b[39m     loss.backward()\n\u001b[32m     22\u001b[39m     optimizer.step()\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     train_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m     train_psnr += calculate_psnr(output, hr)\n\u001b[32m     27\u001b[39m avg_train_loss = train_loss / \u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# 7. TRAINING LOOP\n",
    "# -----------------------\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING STARTED\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "best_val_psnr = 0.0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # ========== TRAINING PHASE ==========\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_psnr = 0.0\n",
    "    \n",
    "    for lr, hr in train_loader:\n",
    "        lr, hr = lr.to(device), hr.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(lr)\n",
    "        loss = criterion(output, hr)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        train_psnr += calculate_psnr(output, hr)\n",
    "    \n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    avg_train_psnr = train_psnr / len(train_loader)\n",
    "    \n",
    "    # ========== VALIDATION PHASE (SIMULTANEOUS) ==========\n",
    "    avg_val_loss, avg_val_psnr = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}]\")\n",
    "    print(f\"  Train -> Loss: {avg_train_loss:.6f} | PSNR: {avg_train_psnr:.2f} dB\")\n",
    "    print(f\"  Val   -> Loss: {avg_val_loss:.6f} | PSNR: {avg_val_psnr:.2f} dB\")\n",
    "    \n",
    "    # Save best model based on validation PSNR\n",
    "    if avg_val_psnr > best_val_psnr:\n",
    "        best_val_psnr = avg_val_psnr\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        print(f\"  ✅ Best model saved! (Val PSNR: {avg_val_psnr:.2f} dB)\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7054cd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model_class, model_path, input_dir, output_dir, device):\n",
    "    \"\"\"\n",
    "    Run super-resolution inference on all images in input_dir\n",
    "    and save results to output_dir.\n",
    "    \"\"\"\n",
    "    # 1️⃣ Load the model\n",
    "    model = model_class().to(device)\n",
    "    state_dict = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Define preprocessing transform\n",
    "    transform = transforms.ToTensor()\n",
    "\n",
    "    # 2️⃣ Process images\n",
    "    image_files = sorted([\n",
    "        f for f in os.listdir(input_dir)\n",
    "        if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "    ])\n",
    "\n",
    "    print(f\"Processing {len(image_files)} images...\\n\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img_name in image_files:\n",
    "            lr_img = Image.open(os.path.join(input_dir, img_name)).convert(\"YCbCr\")\n",
    "            y, cb, cr = lr_img.split()\n",
    "\n",
    "            y_tensor = transform(y).unsqueeze(0).to(device)\n",
    "            sr_y = model(y_tensor).clamp(0.0, 1.0)\n",
    "            sr_y_img = transforms.ToPILImage()(sr_y.squeeze(0).cpu())\n",
    "\n",
    "            cb = cb.resize(sr_y_img.size, Image.BICUBIC)\n",
    "            cr = cr.resize(sr_y_img.size, Image.BICUBIC)\n",
    "            sr_img = Image.merge(\"YCbCr\", [sr_y_img, cb, cr]).convert(\"RGB\")\n",
    "\n",
    "            sr_img.save(os.path.join(output_dir, f\"SR_{img_name}\"))\n",
    "            print(f\"✅ Saved: SR_{img_name}\")\n",
    "#\n",
    "    # print(f\"\\n✅ All {len(image_files)} images processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80b848b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 4 images...\n",
      "\n",
      "✅ Saved: SR_Pasted image (2).png\n",
      "✅ Saved: SR_Pasted image (3).png\n",
      "✅ Saved: SR_Pasted image (4).png\n",
      "✅ Saved: SR_Pasted image.png\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "inference(\n",
    "    model_class=SRCNN,                     # your SRCNN class\n",
    "    model_path=\"/home/akanksh/Akshu/ML/project/best_model.pth\",           # path to saved model\n",
    "    input_dir=\"/home/akanksh/Akshu/ML/project/dataset/raw\",      # LR images\n",
    "    output_dir=\"/home/akanksh/Akshu/ML/project/dataset/out\",  # SR outputs\n",
    "    device=device\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849c5cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
